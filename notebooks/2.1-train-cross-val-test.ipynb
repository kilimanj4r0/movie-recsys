{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training using cross-validation on RecTools model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I train and evaluate diffrent models on each split, using [RecTools models and metrics implementation](https://rectools.readthedocs.io/en/stable/features.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u1.base',\n",
       " 'u1.test',\n",
       " 'u2.base',\n",
       " 'u2.test',\n",
       " 'u3.base',\n",
       " 'u3.test',\n",
       " 'u4.base',\n",
       " 'u4.test',\n",
       " 'u5.base',\n",
       " 'u5.test',\n",
       " 'ua.base',\n",
       " 'ua.test',\n",
       " 'ub.base',\n",
       " 'ub.test']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_USERS = 943\n",
    "N_ITEMS = 1682\n",
    "K = 10\n",
    "data_interim_dir = '../data/interim/'\n",
    "data_filenames = [f'u{t}.{split}' for t in ['1', '2', '3', '4', '5', 'a', 'b'] for split in ['base', 'test']]\n",
    "data_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['u1', 'u2', 'u3', 'u4', 'u5', 'ua', 'ub'])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "data = {}\n",
    "for i in range(0, len(data_filenames), 2):\n",
    "    base_filename, test_filename = data_filenames[i:i+2]\n",
    "    data_title = base_filename.split('.')[0]\n",
    "    with open(data_interim_dir + base_filename + '.pickle', 'rb') as base:\n",
    "        with open(data_interim_dir + test_filename + '.pickle', 'rb') as test:\n",
    "            with open(data_interim_dir + test_filename + '.df.pickle', 'rb') as base_df:\n",
    "                with open(data_interim_dir + test_filename + '.df.pickle', 'rb') as test_df:\n",
    "                    data[data_title] = (pickle.load(base), pickle.load(test), pickle.load(base_df), pickle.load(test_df))\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing 5-fold cross-validation on `u1-u5` splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fold):\n",
    "    return data[f'u{fold}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectools import Columns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def train_and_validate(model, fold_data):\n",
    "    train, test, train_df, test_df = fold_data\n",
    "\n",
    "    model.fit(train)\n",
    "    \n",
    "    recos = model.recommend(\n",
    "        users=train_df[Columns.User].unique(),\n",
    "        dataset=train,\n",
    "        k=K,\n",
    "        filter_viewed=True,\n",
    "    )\n",
    "    recos.rename(columns={Columns.Score: Columns.Weight}, inplace=True)\n",
    "\n",
    "    merged_data = pd.merge(recos, test_df, on=[Columns.User, Columns.Item], suffixes=('_predicted', '_test'))\n",
    "    rmse = np.sqrt(mean_squared_error(merged_data[Columns.Weight + '_test'], merged_data[Columns.Weight + '_predicted']))\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, model_name, num_folds=5):\n",
    "    print(model_name)\n",
    "    \n",
    "    rmse_values = []\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        fold_data = load_data(fold)\n",
    "        fold_rmse = train_and_validate(model, fold_data)\n",
    "        rmse_values.append(fold_rmse)\n",
    "        print(f\"RMSE (Fold {fold}): {fold_rmse}\")\n",
    "\n",
    "    average_rmse = np.mean(rmse_values)\n",
    "    print(f\"Average RMSE (across all folds): {average_rmse}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from rectools.models import PureSVDModel, LightFMWrapperModel, ImplicitALSWrapperModel\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "\n",
    "factors = 10  # Fine-tuned\n",
    "model_svd = PureSVDModel()\n",
    "model_als = ImplicitALSWrapperModel(\n",
    "        AlternatingLeastSquares(factors=factors)\n",
    "        )\n",
    "model_lfm = LightFMWrapperModel(\n",
    "    model=LightFM(no_components=factors, k=K),\n",
    "    epochs=1,  # Fine-tuned\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PureSVDModel\n",
      "RMSE (Fold 1): 2.465804801558191\n",
      "RMSE (Fold 2): 2.1509809413755785\n",
      "RMSE (Fold 3): 2.0662233143866886\n",
      "RMSE (Fold 4): 2.1081675292333175\n",
      "RMSE (Fold 5): 2.152631851093425\n",
      "Average RMSE (across all folds): 2.18876168752944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_validation(model_svd, 'PureSVDModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlternatingLeastSquares\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\py310\\lib\\site-packages\\rectools\\dataset\\features.py:420: UserWarning: Converting sparse features to dense array may cause MemoryError\n",
      "  warnings.warn(\"Converting sparse features to dense array may cause MemoryError\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b7005059fe4be0b0c3dfb3112aa407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9198884f5d9420db9be610a1764ec77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Fold 1): 2.5380366492540736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\py310\\lib\\site-packages\\rectools\\dataset\\features.py:420: UserWarning: Converting sparse features to dense array may cause MemoryError\n",
      "  warnings.warn(\"Converting sparse features to dense array may cause MemoryError\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a08085085949a38c73c12e42122b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0bf757099d4cb2a7a385a57e738016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Fold 2): 2.42103019197958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\py310\\lib\\site-packages\\rectools\\dataset\\features.py:420: UserWarning: Converting sparse features to dense array may cause MemoryError\n",
      "  warnings.warn(\"Converting sparse features to dense array may cause MemoryError\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b002a64c1bec41f9bfbed69373ac049c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed8fc6d9b1c42db9496829e10aa921e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Fold 3): 2.3566056332331047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\py310\\lib\\site-packages\\rectools\\dataset\\features.py:420: UserWarning: Converting sparse features to dense array may cause MemoryError\n",
      "  warnings.warn(\"Converting sparse features to dense array may cause MemoryError\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e8aae76a8247d4bbb81e8082573e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e2e0f24f1f47a3a2346f7db30af94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Fold 4): 2.3608011215578353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\py310\\lib\\site-packages\\rectools\\dataset\\features.py:420: UserWarning: Converting sparse features to dense array may cause MemoryError\n",
      "  warnings.warn(\"Converting sparse features to dense array may cause MemoryError\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a24e0571c5487c8b3af34c8d97495e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c6e0575cb643d5974be9a64143a241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Fold 5): 2.367598727982355\n",
      "Average RMSE (across all folds): 2.4088144648013894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_validation(model_als, 'AlternatingLeastSquares')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightFM\n",
      "RMSE (Fold 1): 28.933907612732494\n",
      "RMSE (Fold 2): 28.994876857271887\n",
      "RMSE (Fold 3): 29.60348985984716\n",
      "RMSE (Fold 4): 29.170035175190396\n",
      "RMSE (Fold 5): 28.775662757717225\n",
      "Average RMSE (across all folds): 29.09559445255183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_validation(model_lfm, 'LightFM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_svd\n",
    "best_model_name = 'PureSVD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on A and B splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectools import Columns\n",
    "from rectools.metrics import NDCG, Accuracy, MAP, MCC, MRR\n",
    "\n",
    "\n",
    "ndcg = NDCG(k=K, log_base=3)\n",
    "acc = Accuracy(k=K)\n",
    "mmap = MAP(k=K)\n",
    "mcc = MCC(k=K)\n",
    "mrr = MRR(k=K)\n",
    "\n",
    "def calculate_metrics(recos, fold_data):\n",
    "    train, test, train_df, test_df = fold_data\n",
    "    metrics = {\n",
    "        'MAP':  mmap.calc(reco=recos, interactions=test_df),\n",
    "        'Accuracy': acc.calc(reco=recos, interactions=test_df, catalog=train_df[Columns.Item]),\n",
    "        'NDCG': ndcg.calc(reco=recos, interactions=test_df),\n",
    "        'MCC': mcc.calc(reco=recos, interactions=test_df, catalog=train_df[Columns.Item]),\n",
    "        'MRR': mrr.calc(reco=recos, interactions=test_df),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate(model, fold_data):\n",
    "    train, test, train_df, test_df = fold_data\n",
    "    model.fit(train)\n",
    "    recos = model.recommend(\n",
    "        users=train_df[Columns.User].unique(),\n",
    "        dataset=train,\n",
    "        k=K,\n",
    "        filter_viewed=True,\n",
    "    )\n",
    "    recos.rename(columns={Columns.Score: Columns.Weight}, inplace=True)\n",
    "    return calculate_metrics(recos, fold_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def print_metrics_table(metrics_dict):\n",
    "    table = []\n",
    "\n",
    "    for metric_name, metric_value in metrics_dict.items():\n",
    "        table.append([metric_name, metric_value])\n",
    "\n",
    "    print(tabulate(table, headers=['Metric', 'Value'], tablefmt='simple'))\n",
    "\n",
    "\n",
    "def test(model, folds=['a', 'b']):\n",
    "    total_metrics = {\n",
    "        'MAP': 0,\n",
    "        'Accuracy': 0,\n",
    "        'NDCG': 0,\n",
    "        'MCC': 0,\n",
    "        'MRR': 0,\n",
    "    }\n",
    "    for fold in folds:\n",
    "        fold_data = load_data(fold)\n",
    "        fold_metrics = train_and_evaluate(model, fold_data)\n",
    "        for metric_name, metric_value in fold_metrics.items():\n",
    "            total_metrics[metric_name] += metric_value\n",
    "        print(f\"Fold {fold}:\")\n",
    "        print_metrics_table(fold_metrics)\n",
    "        print()\n",
    "    average_metrics = {metric_name: total_value / len(folds) for metric_name, total_value in total_metrics.items()}\n",
    "    print(f\"Average across test folds:\")\n",
    "    print_metrics_table(average_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold a:\n",
      "Metric       Value\n",
      "--------  --------\n",
      "MAP       0.149509\n",
      "Accuracy  0.998394\n",
      "NDCG      0.285174\n",
      "MCC       0.242038\n",
      "MRR       0.613322\n",
      "\n",
      "Fold b:\n",
      "Metric       Value\n",
      "--------  --------\n",
      "MAP       0.141989\n",
      "Accuracy  0.99837\n",
      "NDCG      0.273182\n",
      "MCC       0.230786\n",
      "MRR       0.592713\n",
      "\n",
      "Average across test folds:\n",
      "Metric       Value\n",
      "--------  --------\n",
      "MAP       0.145749\n",
      "Accuracy  0.998382\n",
      "NDCG      0.279178\n",
      "MCC       0.236412\n",
      "MRR       0.603017\n"
     ]
    }
   ],
   "source": [
    "test(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
